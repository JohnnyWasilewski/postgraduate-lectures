{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6289be33",
   "metadata": {},
   "source": [
    "# Uczenie aktywne (Active learning)\n",
    "Uczenie aktywne jest przykładem zagadnienia uczenia maszynowego w którym algorytm może poprosić o etykiety niektórych danych. Obecnie stosuje się wiele strategii wyboru danych do etykietowania. Jedna z najprostszych metod polega na wyborze danych które dadzą najwięcej informacji, tj. danych których model jest najbardziej niepewny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "73c6adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset, ConcatDataset, TensorDataset, SubsetRandomSampler, DataLoader\n",
    "from laplace import Laplace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "af430ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(20, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "def train_nn(train_dataloader, epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    my_nn = MyNN()\n",
    "\n",
    "    optimizer = torch.optim.Adam(my_nn.parameters(), lr = 0.01)\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = my_nn(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return my_nn\n",
    "\n",
    "def train_bnn(train_dataloader, my_nn):\n",
    "    la = Laplace(my_nn, 'classification',\n",
    "             subset_of_weights='all',\n",
    "             hessian_structure='full')\n",
    "    la.fit(train_dataloader)\n",
    "    return la\n",
    "\n",
    "def model_eval(model, dataloader):\n",
    "    softmax = nn.Softmax(dim=0)\n",
    "    result = []\n",
    "    num_samples=0\n",
    "    for X, y in dataloader:\n",
    "        result.append((torch.argmax(softmax(model(X)), dim=1) == y).int().numpy())        \n",
    "        num_samples+=X.shape[0]\n",
    "    return np.sum(np.concatenate(result)) / num_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "b8fd8f09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def al():\n",
    "    X, y = make_classification(2000, class_sep = 0.8)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    scores_random, scores_active = list(), list()\n",
    "    batch_size=100\n",
    "    sizes = np.arange(100, X_train_original.shape[0], step=batch_size)\n",
    "    \n",
    "    dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float), torch.tensor(y_train))\n",
    "    full_dataloader = DataLoader(dataset, batch_size = batch_size)\n",
    "\n",
    "    al_indices = np.arange(sizes[0])\n",
    "    al_indices_left = np.setdiff1d(np.arange(X_train.shape[0]), al_indices)\n",
    "\n",
    "    ds_al_train = Subset(dataset, range(batch_size))\n",
    "    ds_al_test = Subset(dataset, range(batch_size, X_train.shape[0]))\n",
    "\n",
    "    scores_active = []\n",
    "    scores_random = []\n",
    "\n",
    "    for train_dataset_size in sizes:\n",
    "        #print(f\"train lengt {len(ds_al_train)} and predict length = {len(ds_al_test)}\")\n",
    "        train_loader_al = DataLoader(ds_al_train, batch_size=batch_size)\n",
    "        predict_loader_al = DataLoader(ds_al_test, batch_size=batch_size)\n",
    "\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                                  sampler=SubsetRandomSampler(range(train_dataset_size)))\n",
    "        predict_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "            sampler = SubsetRandomSampler(range(train_dataset_size, X_train.shape[0]))\n",
    "        )\n",
    "        #print(f\"random {train_dataset_size}, preds = {len(range(train_dataset_size, X_train.shape[0]))}\")\n",
    "\n",
    "        my_nn_al = train_nn(train_loader_al)\n",
    "        my_bnn = train_bnn(train_loader_al, my_nn_al)\n",
    "        my_nn = train_nn(train_loader)\n",
    "        scores_active.append(model_eval(my_nn_al, full_dataloader))\n",
    "        scores_random.append(model_eval(my_nn, full_dataloader))\n",
    "        if train_dataset_size == sizes[-1]:\n",
    "            break\n",
    "        pred_vars = []\n",
    "        for X, y in predict_loader_al:\n",
    "            a = my_bnn.predictive_samples(X, pred_type='nn', n_samples= 1000)\n",
    "            pred_vars.append(torch.var(a, dim=0)[:, 0].numpy())\n",
    "\n",
    "        pred_vars_np = np.concatenate(pred_vars)\n",
    "        idxs = pred_vars_np.argsort()\n",
    "\n",
    "        ds_al_train = torch.utils.data.ConcatDataset(\n",
    "            (ds_al_train, Subset(ds_al_test, idxs[:batch_size]))\n",
    "        )\n",
    "        ds_al_test = Subset(ds_al_test, np.setdiff1d(np.arange(len(ds_al_test)), idxs[:batch_size]))    \n",
    "    return sizes, scores_random, scores_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(10,10))\n",
    "for ax in axs.flatten():\n",
    "    sizes, scores_random, scores_active = al()\n",
    "    ax.scatter(sizes, scores_random, c='red')\n",
    "    ax.scatter(sizes, scores_active, c='blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
